"""
This file handles the optimization of VaRKG including the initial condition generation.
Initial conditions are generated using a heuristic based on one-shot-kg initial conditions.
It uses either LBFGS or ADAM to optimize the problem.
The code here assumes the standard variable bounds of unit-hypercube.
"""
import torch
from botorch.optim import gen_batch_initial_conditions
from botorch.utils import standardize
from torch import Tensor
from typing import Optional, Union, Dict
from VaR_KG import VaRKG, InnerVaR
from botorch.gen import gen_candidates_scipy, gen_candidates_torch


def gen_one_shot_VaRKG_initial_conditions(
    acq_function: VaRKG,
    inner_solutions: Tensor,
    inner_vals: Tensor,
    bounds: Tensor,
    num_restarts: int,
    raw_samples: int,
    options: Optional[Dict[str, Union[bool, float, int]]] = None,
) -> Optional[Tensor]:
    r"""
    See the explanation below to get an idea of how this works, though it is not completely accurate anymore.
    The code has been modified to work with VaRKG instead.
    Generate a batch of smart initializations for qKnowledgeGradient.

    This function generates initial conditions for optimizing one-shot KG using
    the maximizer of the posterior objective. Intutively, the maximizer of the
    fantasized posterior will often be close to a maximizer of the current
    posterior. This function uses that fact to generate the initital conditions
    for the fantasy points. Specifically, a fraction of `1 - frac_random` (see
    options) is generated by sampling from the set of maximizers of the
    posterior objective (obtained via random restart optimization) according to
    a softmax transformation of their respective values. This means that this
    initialization strategy internally solves an acquisition function
    maximization problem. The remaining `frac_random` fantasy points as well as
    all `q` candidate points are chosen according to the standard initialization
    strategy in `gen_batch_initial_conditions`.

    Args:
        acq_function: The qKnowledgeGradient instance to be optimized.
        inner_solutions: The solutions to inner optimization problem. As many
            as possible should be provided.
        inner_vals: The corresponding objective values of the inner solutions.
        bounds: A `2 x d` tensor of lower and upper bounds for each column of
            task features.
        q: The number of candidates to consider.
        num_restarts: The number of starting points for multistart acquisition
            function optimization.
        raw_samples: The number of raw samples to consider in the initialization
            heuristic.
        options: Options for initial condition generation. These contain all
            settings for the standard heuristic initialization from
            `gen_batch_initial_conditions`. In addition, they contain
            `frac_random` (the fraction of fully random fantasy points),
            `num_inner_restarts` and `raw_inner_samples` (the number of random
            restarts and raw samples for solving the posterior objective
            maximization problem, respectively) and `eta` (temperature parameter
            for sampling heuristic from posterior objective maximizers).

    Returns:
        A `num_restarts x q' x d` tensor that can be used as initial conditions
        for `optimize_acqf()`. Here `q' = q + num_fantasies` is the total number
        of points (candidate points plus fantasy points).

    Example:
         qKG = qKnowledgeGradient(model, num_fantasies=64)
         bounds = torch.tensor([[0., 0.], [1., 1.]])
         Xinit = gen_one_shot_kg_initial_conditions(
             qKG, bounds, q=3, num_restarts=10, raw_samples=512,
             options={"frac_random": 0.25},
         )
    """
    options = options or {}
    frac_random: float = options.get("frac_random", 0.1)
    if not 0 < frac_random < 1:
        raise ValueError(
            f"frac_random must take on values in (0,1). Value: {frac_random}"
        )
    # q = acq_function.q
    num_fantasies = acq_function.num_fantasies
    # d = acq_function.dim
    dim_x = acq_function.dim_x
    # bounds = Tensor([[0], [1]]).repeat(1, q * d + num_fantasies * dim_x)

    ics = gen_batch_initial_conditions(
        acq_function=acq_function,
        bounds=bounds,
        q=1,
        num_restarts=num_restarts,
        raw_samples=raw_samples,
        options=options,
    )

    fantasy_cands, fantasy_vals = inner_solutions, inner_vals

    # sampling from the optimizers
    n_value = int((1 - frac_random) * num_fantasies)  # number of non-random ICs
    eta = options.get("eta", 2.0)
    weights = torch.exp(eta * standardize(fantasy_vals))
    idx = torch.multinomial(weights, num_restarts * n_value, replacement=True)

    # set the respective initial conditions to the sampled optimizers
    # ics[..., -n_value:, :] = fantasy_cands[idx, 0].view(num_restarts, n_value, -1)
    ics[..., -n_value * dim_x:] = fantasy_cands[idx, 0].view(num_restarts, 1, n_value * dim_x)
    return ics