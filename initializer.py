"""
This file handles the optimization of VaRKG including the initial condition generation.
Initial conditions are generated using a heuristic based on one-shot-kg initial conditions.
It uses either LBFGS or ADAM to optimize the problem.
The code here assumes the standard variable bounds of unit-hypercube.
"""
import torch
from botorch.utils import standardize, draw_sobol_samples
from torch import Tensor
from typing import Optional, Union, Dict
from VaR_KG import VaRKG, InnerVaR


def gen_one_shot_VaRKG_initial_conditions(
        acq_function: VaRKG,
        inner_solutions: Tensor,
        inner_vals: Tensor,
        bounds: Tensor,
        num_restarts: int,
        raw_samples: int,
        options: Optional[Dict[str, Union[bool, float, int]]] = None,
) -> Optional[Tensor]:
    r"""
    See the explanation below to get an idea of how this works, though it is not completely accurate anymore.
    The code has been modified to work with VaRKG instead.
    It has been modified significantly and combined with gen_batch_initial_conditions for optimal candidate
    generation.

    Generate a batch of smart initializations for qKnowledgeGradient.

    This function generates initial conditions for optimizing one-shot KG using
    the maximizer of the posterior objective. Intutively, the maximizer of the
    fantasized posterior will often be close to a maximizer of the current
    posterior. This function uses that fact to generate the initital conditions
    for the fantasy points. Specifically, a fraction of `1 - frac_random` (see
    options) is generated by sampling from the set of maximizers of the
    posterior objective (obtained via random restart optimization) according to
    a softmax transformation of their respective values. This means that this
    initialization strategy internally solves an acquisition function
    maximization problem. The remaining `frac_random` fantasy points as well as
    all `q` candidate points are chosen according to the standard initialization
    strategy in `gen_batch_initial_conditions`.

    Args:
        acq_function: The qKnowledgeGradient instance to be optimized.
        inner_solutions: The solutions to inner optimization problem. As many
            as possible should be provided.
        inner_vals: The corresponding objective values of the inner solutions.
        bounds: A `2 x d` tensor of lower and upper bounds for each column of
            task features.
        q: The number of candidates to consider.
        num_restarts: The number of starting points for multistart acquisition
            function optimization.
        raw_samples: The number of raw samples to consider in the initialization
            heuristic.
        options: Options for initial condition generation. These contain all
            settings for the standard heuristic initialization from
            `gen_batch_initial_conditions`. In addition, they contain
            `frac_random` (the fraction of fully random fantasy points),
            `num_inner_restarts` and `raw_inner_samples` (the number of random
            restarts and raw samples for solving the posterior objective
            maximization problem, respectively) and `eta` (temperature parameter
            for sampling heuristic from posterior objective maximizers).

    Returns:
        A `num_restarts x q' x d` tensor that can be used as initial conditions
        for `optimize_acqf()`. Here `q' = q + num_fantasies` is the total number
        of points (candidate points plus fantasy points).

    Example:
         qKG = qKnowledgeGradient(model, num_fantasies=64)
         bounds = torch.tensor([[0., 0.], [1., 1.]])
         Xinit = gen_one_shot_kg_initial_conditions(
             qKG, bounds, q=3, num_restarts=10, raw_samples=512,
             options={"frac_random": 0.25},
         )
    """
    options = options or {}
    frac_random: float = options.get("frac_random", 0.1)
    if not 0 < frac_random < 1:
        raise ValueError(
            f"frac_random must take on values in (0,1). Value: {frac_random}"
        )
    num_fantasies = acq_function.num_fantasies
    dim_x = acq_function.dim_x

    q = 1
    n = raw_samples
    X_rnd = draw_sobol_samples(bounds=bounds, n=n, q=q)

    fantasy_cands, fantasy_vals = inner_solutions, inner_vals

    # sampling from the optimizers
    n_value = int((1 - frac_random) * num_fantasies)  # number of non-random ICs
    eta = options.get("eta", 2.0)
    weights = torch.exp(eta * standardize(fantasy_vals))
    idx = torch.multinomial(weights, num_restarts * n_value, replacement=True)

    # set the respective initial conditions to the sampled optimizers
    # we add some extra noise here to avoid all the samples being the same
    X_rnd[..., -n_value * dim_x:] = fantasy_cands[idx, 0].view(num_restarts, 1, n_value * dim_x)\
                                        .repeat(int(raw_samples/num_restarts), 1, 1) \
                                        + torch.randn((raw_samples, 1, n_value * dim_x)) * 0.01

    with torch.no_grad():
        Y_rnd = acq_function(X_rnd)
    batch_initial_conditions = initialize_q_batch(
        X=X_rnd, Y=Y_rnd, n=num_restarts
    )
    return batch_initial_conditions


def initialize_q_batch(X: Tensor, Y: Tensor, n: int, eta: float = 1.0) -> Tensor:
    r"""Heuristic for selecting initial conditions for candidate generation.

    This heuristic selects points from `X` (without replacement) with probability
    proportional to `exp(eta * Z)`, where `Z = (Y - mean(Y)) / std(Y)` and `eta`
    is a temperature parameter.

    When using an acquisiton function that is non-negative and possibly zero
    over large areas of the feature space (e.g. qEI), you should use
    `initialize_q_batch_nonneg` instead.

    Args:
        X: A `b x q x d` tensor of `b` samples of `q`-batches from a `d`-dim.
            feature space. Typically, these are generated using qMC sampling.
        Y: A tensor of `b` outcomes associated with the samples. Typically, this
            is the value of the batch acquisition function to be maximized.
        n: The number of initial condition to be generated. Must be less than `b`.
        eta: Temperature parameter for weighting samples.

    Returns:
        A `n x q x d` tensor of `n` `q`-batch initial conditions.

    Example:

    """
    n_samples = X.shape[0]
    if n > n_samples:
        raise RuntimeError(
            f"n ({n}) cannot be larger than the number of "
            f"provided samples ({n_samples})"
        )
    elif n == n_samples:
        return X

    Ystd = Y.std()
    if Ystd == 0:
        warnings.warn(
            "All acqusition values for raw samples points are the same. "
            "Choosing initial conditions at random.",
            BadInitialCandidatesWarning,
        )
        return X[torch.randperm(n=n_samples, device=X.device)][:n]

    max_val, max_idx = torch.max(Y, dim=0)
    Z = (Y - Y.mean()) / Ystd
    etaZ = eta * Z
    weights = torch.exp(etaZ)
    while torch.isinf(weights).any():
        etaZ *= 0.5
        weights = torch.exp(etaZ)
    idcs = torch.multinomial(weights, n)
    # make sure we get the maximum
    if max_idx not in idcs:
        idcs[-1] = max_idx
    return X[idcs]
